{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2f594964",
   "metadata": {},
   "source": [
    "## Setting up the environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e3bc0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import google.generativeai as genai \n",
    "from IPython.display import display\n",
    "from IPython.display import Markdown\n",
    "os.environ[\"GEMINI_API_KEY\"] = <your_gemini_api>\n",
    "genai.configure(api_key=os.environ[\"GEMINI_API_KEY\"])\n",
    "import re"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1ab5e0f2",
   "metadata": {},
   "source": [
    "## Indexing the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "cf0f564d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypdf import PdfReader\n",
    "\n",
    "def load_pdf(file_path):\n",
    "    \"\"\"\n",
    "    Reads the text content from a PDF file and returns it as a single string.\n",
    "\n",
    "    Parameters:\n",
    "    - file_path (str): The file path to the PDF file.\n",
    "\n",
    "    Returns:\n",
    "    - str: The concatenated text content of all pages in the PDF.\n",
    "    \"\"\"\n",
    "    # Logic to read pdf\n",
    "    reader = PdfReader(file_path)\n",
    "\n",
    "    # Loop over each page and store it in a variable\n",
    "    text = \"\"\n",
    "    for page in reader.pages:\n",
    "        text += page.extract_text()\n",
    "\n",
    "    return text\n",
    "\n",
    "# replace the path with your file path\n",
    "pdf_text = load_pdf(file_path=\"gradients without backprop.pdf\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0e02a38e",
   "metadata": {},
   "source": [
    "## Splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "36847d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text(text: str):\n",
    "    \"\"\"\n",
    "    Splits a text string into a list of non-empty substrings based on the specified pattern.\n",
    "    The \"\\n \\n\" pattern will split the document para by para\n",
    "    Parameters:\n",
    "    - text (str): The input text to be split.\n",
    "\n",
    "    Returns:\n",
    "    - List[str]: A list containing non-empty substrings obtained by splitting the input text.\n",
    "\n",
    "    \"\"\"\n",
    "    split_text = re.split('\\n \\n', text)\n",
    "    return [i for i in split_text if i != \"\"]\n",
    "\n",
    "text  = split_text(text=pdf_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "72eeb02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "from chromadb import Documents, EmbeddingFunction, Embeddings\n",
    "import os\n",
    "\n",
    "class GeminiEmbeddingFunction(EmbeddingFunction):\n",
    "    \"\"\"\n",
    "    Custom embedding function using the Gemini AI API for document retrieval.\n",
    "\n",
    "    This class extends the EmbeddingFunction class and implements the __call__ method\n",
    "    to generate embeddings for a given set of documents using the Gemini AI API.\n",
    "\n",
    "    Parameters:\n",
    "    - input (Documents): A collection of documents to be embedded.\n",
    "\n",
    "    Returns:\n",
    "    - Embeddings: Embeddings generated for the input documents.\n",
    "\n",
    "    Raises:\n",
    "    - ValueError: If the Gemini API Key is not provided as an environment variable (GEMINI_API_KEY).\n",
    "\n",
    "    Example:\n",
    "    >>> gemini_embedding_function = GeminiEmbeddingFunction()\n",
    "    >>> input_documents = Documents([\"Document 1\", \"Document 2\", \"Document 3\"])\n",
    "    >>> embeddings_result = gemini_embedding_function(input_documents)\n",
    "    >>> print(embeddings_result)\n",
    "    Embeddings for the input documents generated by the Gemini AI API.\n",
    "    \"\"\"\n",
    "    def __call__(self, input: Documents) -> Embeddings:\n",
    "        gemini_api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "        if not gemini_api_key:\n",
    "            raise ValueError(\"Gemini API Key not provided. Please provide GEMINI_API_KEY as an environment variable\")\n",
    "        genai.configure(api_key=gemini_api_key)\n",
    "        model = \"models/embedding-001\"\n",
    "        title = \"Custom query\"\n",
    "        return genai.embed_content(model=model,\n",
    "                                   content=input,\n",
    "                                   task_type=\"retrieval_document\",\n",
    "                                   title=title)[\"embedding\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "055655b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "def create_chroma_db(documents, path, name):\n",
    "    \"\"\"\n",
    "    Creates a Chroma database using the provided documents, path, and collection name.\n",
    "\n",
    "    Parameters:\n",
    "    - documents: An iterable of documents to be added to the Chroma database.\n",
    "    - path (str): The path where the Chroma database will be stored.\n",
    "    - name (str): The name of the collection within the Chroma database.\n",
    "\n",
    "    Returns:\n",
    "    - Tuple[chromadb.Collection, str]: A tuple containing the created Chroma Collection and its name.\n",
    "    \"\"\"\n",
    "    chroma_client = chromadb.PersistentClient(path=path)\n",
    "    db = chroma_client.create_collection(name=name, embedding_function=GeminiEmbeddingFunction())\n",
    "\n",
    "    for i, d in enumerate(documents):\n",
    "        db.add(documents=d, ids=str(i))\n",
    "\n",
    "    return db, name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e4eb23c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "db,name =create_chroma_db(documents=text, path=\"contents\", name=\"gradient_rag\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0fb2d0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_chroma_collection(path, name):\n",
    "    \"\"\"\n",
    "    Loads an existing Chroma collection from the specified path with the given name.\n",
    "\n",
    "    Parameters:\n",
    "    - path (str): The path where the Chroma database is stored.\n",
    "    - name (str): The name of the collection within the Chroma database.\n",
    "\n",
    "    Returns:\n",
    "    - chromadb.Collection: The loaded Chroma Collection.\n",
    "    \"\"\"\n",
    "    chroma_client = chromadb.PersistentClient(path=path)\n",
    "    db = chroma_client.get_collection(name=name, embedding_function=GeminiEmbeddingFunction())\n",
    "\n",
    "    return db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1b5f20a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "db=path=load_chroma_collection(\"contents\", name=\"gradient_rag\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "80d72e3c",
   "metadata": {},
   "source": [
    "## Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "415a393a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relevant_passage(query, db, n_results):\n",
    "  passage = db.query(query_texts=[query], n_results=n_results)['documents'][0]\n",
    "  return passage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "789dceab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 3 is greater than number of elements in index 1, updating n_results = 1\n"
     ]
    }
   ],
   "source": [
    "relevant_text = get_relevant_passage(\"Gradients\",db,3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ace953c1",
   "metadata": {},
   "source": [
    "## Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "95842b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_rag_prompt(query, relevant_passage):\n",
    "  escaped = relevant_passage.replace(\"'\", \"\").replace('\"', \"\").replace(\"\\n\", \" \")\n",
    "  prompt = (\"\"\"You are a helpful and informative bot that answers questions using text from the reference passage included below. \\\n",
    "  Be sure to respond in a complete sentence, being comprehensive, including all relevant background information. \\\n",
    "  However, you are talking to a non-technical audience, so be sure to break down complicated concepts and \\\n",
    "  strike a friendly and converstional tone. \\\n",
    "  If the passage is irrelevant to the answer, you may ignore it.\n",
    "  QUESTION: '{query}'\n",
    "  PASSAGE: '{relevant_passage}'\n",
    "\n",
    "  ANSWER:\n",
    "  \"\"\").format(query=query, relevant_passage=escaped)\n",
    "\n",
    "  return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1ae02da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "def generate_response(prompt):\n",
    "    gemini_api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "    if not gemini_api_key:\n",
    "        raise ValueError(\"Gemini API Key not provided. Please provide GEMINI_API_KEY as an environment variable\")\n",
    "    genai.configure(api_key=gemini_api_key)\n",
    "    model = genai.GenerativeModel('gemini-pro')\n",
    "    answer = model.generate_content(prompt)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer(db,query):\n",
    "    #retrieve top 3 relevant text chunks\n",
    "    relevant_text = get_relevant_passage(query,db,n_results=3)\n",
    "    prompt = make_rag_prompt(query, \n",
    "                             relevant_passage=\"\".join(relevant_text)) # joining the relevant chunks to create a single passage\n",
    "    answer = generate_response(prompt)\n",
    "\n",
    "    return answer\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "76619bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 3 is greater than number of elements in index 1, updating n_results = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The forward gradient is an unbiased estimator of the gradient, defined as the directional derivative multiplied by the direction vector .\n"
     ]
    }
   ],
   "source": [
    "\n",
    "db=load_chroma_collection(path=\"contents\", #replace with path of your persistent directory\n",
    "                          name=\"gradient_rag\") #replace with the collection name\n",
    "\n",
    "answer = generate_answer(db,query=\"what is a forward gradient??\")\n",
    "print(answer.candidates[0].content.parts[0].text)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
